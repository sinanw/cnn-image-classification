{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks - Image Classification [using Pytorch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check tensorflow version\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LOADING & TRANSFORMING DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used is [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html), which is a widely used benchmark dataset in the field of computer vision and machine learning. It consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. It serves as a standard dataset for training and evaluating machine learning algorithms, particularly for image classification tasks.\n",
    "\n",
    "The classes are: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before loading the dataset, we need to initialize data augmentation and image transformations to avoid over fitting. This helps to increase the diversity of the dataset and improve the generalization ability of the CNN model.\n",
    "\n",
    "Transformations of training images are:\n",
    "- Randomly rotate images\n",
    "- Center crop to the images\n",
    "- Randomly flip images horizontally\n",
    "- Randomly changing the brightness, contrast, saturation, and hue of the image (color jitter)\n",
    "- Scale the pixel values of the images to be in the range [0, 1] (automatically done when converting to tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating transformer for training data as a series of steps\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating transformer for testing data as a series of steps - without augmentation\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By separating the transformation pipelines for training and testing, we ensure that the model is trained with data augmentations that help it generalize better, while the test data remains consistent and unmodified to accurately evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset from pytorch library\n",
    "data_train = torchvision.datasets.CIFAR10(root=\"../data/raw\", train=True, download=True, transform=transform_train)\n",
    "data_test = torchvision.datasets.CIFAR10(root=\"../data/raw\", train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loaders\n",
    "train_loader = torch.utils.data.DataLoader(data_train, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(data_test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. BUILDING CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Define the convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Define the pooling layers\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # Define the fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)  # 8 * 8 * 6 is the flattened dimension after pooling\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)  # 10 output units for 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Apply convolutional layers with ReLU activation and pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Flatten the output from the convolutional layers\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        \n",
    "        # Apply fully connected layers with ReLU activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # Apply the output layer with softmax activation\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "cnn = CNN()\n",
    "\n",
    "# Define the loss function (cross-entropy loss)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer (Adam optimizer)\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. TRAINING CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize metrics function\n",
    "def compute_metrics(outputs, labels):\n",
    "     # Convert model outputs to predicted labels\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    # Convert labels and predictions to numpy arrays\n",
    "    labels = labels.cpu().numpy()\n",
    "    preds = preds.cpu().numpy()\n",
    "    \n",
    "    # Calculate accuracy, F1-score, precision, and recall\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    precision = precision_score(labels, preds, average='weighted', zero_division=1)\n",
    "    recall = recall_score(labels, preds, average='weighted', zero_division=1)\n",
    "    \n",
    "    return accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs to train the model\n",
    "num_epochs = 25\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move your model to the GPU\n",
    "cnn.to(device)\n",
    "\n",
    "# Set model to training mode\n",
    "cnn.train()\n",
    "\n",
    "# Lists to store training and validation metrics\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    running_f1 = 0.0\n",
    "    running_precision = 0.0\n",
    "    running_recall = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        \n",
    "         # Move inputs and labels to the GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)     \n",
    "        \n",
    "        # Initialize parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: compute model output\n",
    "        outputs = cnn(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass: compute gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy, f1, precision, recall = compute_metrics(outputs, labels)\n",
    "        running_accuracy += accuracy\n",
    "        running_f1 += f1\n",
    "        running_precision += precision\n",
    "        running_recall += recall\n",
    "    \n",
    "    # Calculate average metrics for each epoch\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    avg_accuracy = running_accuracy / len(train_loader)\n",
    "    avg_f1 = running_f1 / len(train_loader)\n",
    "    avg_precision = running_precision / len(train_loader)\n",
    "    avg_recall = running_recall / len(train_loader)\n",
    "    \n",
    "    # Store training accuracy\n",
    "    train_accuracies.append(avg_accuracy)\n",
    "    \n",
    "   # Set model to evaluation mode\n",
    "    cnn.eval()\n",
    "    \n",
    "    # Initialize evaluation metrics\n",
    "    eval_loss = 0.0\n",
    "    eval_accuracy = 0.0\n",
    "    eval_f1 = 0.0\n",
    "    eval_precision = 0.0\n",
    "    eval_recall = 0.0\n",
    "    \n",
    "    # Disable gradient computation for evaluation\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            \n",
    "            # Move inputs and labels to the GPU\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass: compute model output\n",
    "            outputs = cnn(inputs)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Accumulate evaluation loss\n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            accuracy, f1, precision, recall = compute_metrics(outputs, labels)\n",
    "            eval_accuracy += accuracy\n",
    "            eval_f1 += f1\n",
    "            eval_precision += precision\n",
    "            eval_recall += recall\n",
    "    \n",
    "    # Calculate average metrics for the evaluation set for each epoch\n",
    "    avg_eval_loss = eval_loss / len(test_loader)\n",
    "    avg_eval_accuracy = eval_accuracy / len(test_loader)\n",
    "    avg_eval_f1 = eval_f1 / len(test_loader)\n",
    "    avg_eval_precision = eval_precision / len(test_loader)\n",
    "    avg_eval_recall = eval_recall / len(test_loader)\n",
    "    \n",
    "    # Store validation accuracy\n",
    "    val_accuracies.append(avg_eval_accuracy)\n",
    "    \n",
    "    # Print average metrics for the epoch\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "          f'accuracy: {avg_accuracy:.4f} - f1_score: {avg_f1:.4f} - loss: {avg_loss:.4f} - '\n",
    "          f'precision: {avg_precision:.4f} - recall: {avg_recall:.4f} - '\n",
    "          f'val_accuracy: {avg_eval_accuracy:.4f} - val_f1_score: {avg_eval_f1:.4f} - val_loss: {avg_eval_loss:.4f} - '\n",
    "          f'val_precision: {avg_eval_precision:.4f} - val_recall: {avg_eval_recall:.4f}')\n",
    "        \n",
    "    # Set model back to training mode\n",
    "    cnn.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. PERFORMANCE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(train_accuracies)\n",
    "plt.plot(val_accuracies)\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
